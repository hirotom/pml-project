---
title: "Practical Machine Learning - Project: Predicting how well barbel lifts are performed"
author: "Hiroto Miyake"
date: "Saturday, January 24, 2015"
output: html_document
---

### Executive Summary
Predictive modeling was developed on a training data that measured various body motions while performing barbell lifts correctly and incorrectly in 5 different classified ways.  Random forest method with 5-fold cross validation was employed for the modeling, which resulted in 99% estimated out-of-sample accuracy.

### 1. Objective
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. 

One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, the goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset)

The objective of this project is to predict the manner in which they did the exercise. This is the "classe" variable in the training set. You may use any of the other variables to predict with. You should create a report describing how you built your model, how you used cross validation, what you think the expected out of sample error is, and why you made the choices you did. You will also use your prediction model to predict 20 different test cases. 

1. Submission should consist of a link to a Github repo with  R markdown and compiled HTML file describing the analysis.
2. Apply machine learning algorithm to the 20 test cases available in the test data above. Please submit predictions in appropriate format to the programming assignment for automated grading.

### 2. Load source data

Downloaded two files and read into data frames.  
* training data contained 19622 rows and 160 columns.
* test data contained 20 rows and 160 columns.
```{r a_load_data}
#download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", "pml-training.csv")
#download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", "pml-testing.csv") 
df_train <- read.csv("pml-training.csv")
df_test <- read.csv("pml-testing.csv")
dim(df_train)
dim(df_test)
```

### 3. Clean up training data

To make prediction more manageable, reduced the number of columns from 160 to 53 to reduce the number of predictors by...
1. Remove data identification columns not relavent for prediction (first 7 columns).
2) Remove unused columns (having entirely NA values) in the test data.  These columns cannot be used as predictors in the model.   
```{r b_clean_data}
df_train <- df_train[, -c(1,2,3,4,5,6,7)]
df_test <- df_test[, -c(1,2,3,4,5,6,7)]
df_train <- df_train[, colSums(is.na(df_test)) != nrow(df_test)]
df_test <- df_test[, colSums(is.na(df_test)) != nrow(df_test)]
ncol(df_train)
colnames(df_train)[53]
```
53rd column of the training data is the outcome variable "classe"

### 4. Develop prediction from the training data

Training data has been further splitinto training and test subset.  60% of the training data has been reserved to develop prediction model, and the remaining has been reserved to test that model out of development sample.
```{r c_subset}
library(caret)
set.seed(32323)
inTrain <- createDataPartition(y=df_train$classe, p=0.6, list=FALSE)
training <- df_train[inTrain,]
testing <- df_train[-inTrain,]
```

Random forest method has been chosen to develop the prediction, because the outcome is a classification type data.
```{r d_predict1}
library(randomForest)
fit1 <- randomForest(classe ~. , data=training)
pred1 <- predict(fit1, testing[,-53])
confusionMatrix(pred1, testing$classe)
```
The randon forest model above resulted in 99.31% out-of-sample accuracy.  The high accuracy of the model indicates potential over-fitting.

To reduce the risk of over-fitting, another random forest prediction was developed using k-fold cross-validation (5-fold).
```{r e_predict2}
fit2 <- train(classe ~ ., method="rf", data=training, trControl=trainControl(method="cv", number=5))
pred2 <- predict(fit2, testing[,-53])
confusionMatrix(pred2, testing$classe)
```
Random forest model with 5-fold cross validation resulted in 99.06% out-of-sample accuracy.  The consistency in accuracy between the non-cross-validated and the cross-validated models confirmed that risk of over-fitting is minimal. 
This is the final model.

### 5. Run prediction on test data set

The final model was used to perform prediction of the test data set.
```{r f_predict3}
pred3 <- predict(fit2, df_test)
pred3
```

Output result files was prepared as instructed.
```{r g_output}
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(pred3)
```

